{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "47f8af98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ae3243",
   "metadata": {},
   "source": [
    "This notebook takes all the test and training samples and adds labels using the data avialable in the GCMS and EGAMS contests. The function takes the filenames which correspond to the sample id and then add labels which are in two sets:\n",
    "1. label: \"basalt, carbonate, chloride, iron_oxide, oxalate, oxychlorine, phyllosilicate, silicate, sulfate, sulfide\"\n",
    "2. label_1: \"aromatic, hydrocarbon, carboxylic acid, nitrogen_bearing_compound, chlorine_bearing_compound, sulfur_bearing_compound, alcohol, other_oxygen_bearing_compound, mineral\n",
    "\n",
    "The generated dataframe includes four columns such that:\n",
    "column_1 : index_id (starting from 1 to the number of samples)\n",
    "column_2 : sample_id from GSFC\n",
    "column_3 : sample data with columns representing 'time' at which the measurement is made, 'mass' of the module, and 'intensity' of the sample released\n",
    "column_4 : label set 1\n",
    "column_5 : label_1 set 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f32de22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the file names, and label names for the dataset you want to use\n",
    "dir_samples      = '/home/arushi/Desktop/FDL_2024/Data_from_Goddard/EGAMS_challenge/EGAMS_post_challenge-20240617T193152Z-001/EGAMS_post_challenge/'\n",
    "dir_label_name   = '/home/arushi/Desktop/FDL_2024/Data_from_Goddard/EGAMS_challenge/EGAMS_post_challenge-20240617T193152Z-001/EGAMS_post_challenge/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "56d5f63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test to see if we get the sample id from the filename correctly\n",
    "file_names  = glob(dir_samples + 'test_features/' + '*.csv')\n",
    "label_file  = dir_label_name + 'test_labels.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a9f1ed72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Indx': 1,\n",
       " 'sample_id': 'S1417',\n",
       " 'Data': {'time': [array([   0.   ,    0.   ,    0.   , ..., 1656.605, 1656.605, 1656.605])],\n",
       "  'mass': [array([ 29.991,  29.991,  29.991, ..., 999.819, 999.819, 999.819])],\n",
       "  'intensity': [array([ 0.,  1.,  2., ..., 97., 98., 99.])]},\n",
       " 'label': {'basalt': 0,\n",
       "  'carbonate': 0,\n",
       "  'chloride': 0,\n",
       "  'iron_oxide': 0,\n",
       "  'oxalate': 0,\n",
       "  'oxychlorine': 1,\n",
       "  'phyllosilicate': 0,\n",
       "  'silicate': 0,\n",
       "  'sulfate': 0,\n",
       "  'sulfide': 0}}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this cell is just for previweing how the output data would be structured\n",
    "num = 1\n",
    "\n",
    "data_file           = np.loadtxt(file_names[0], skiprows=1, delimiter=\",\")\n",
    "df = pd.read_csv(label_file) \n",
    "sample_id           = file_names[0].split('/')[-1].split('.')[0]\n",
    "df[df['sample_id'] == file_names[0].split('/')[-1].split('.')[0]].iloc[0][1:].to_dict()\n",
    "my_dict =  {'Indx': num, 'sample_id': sample_id, 'Data': {'time': [data_file[:, 0]], \\\n",
    "                                                          'mass': [data_file[:, 1]], \\\n",
    "                                                          'intensity': [data_file[:, 2]]}, \\\n",
    "           'label': df[df['sample_id'] == file_names[0].split('/')[-1].split('.')[0]].iloc[0][1:].to_dict()}\n",
    "my_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "288e9eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_cube (filename, num):\n",
    "    '''\n",
    "    This function takes the mass spectrometer data from the sample and generates \n",
    "    a dictionary with the columns specifying the index, sample_id, mass spec data, \n",
    "    and lables. We do this to create a merged data from all the samples with their\n",
    "    labels attached\n",
    "    \n",
    "    Input Parameters\n",
    "        ----------\n",
    "        filename : str\n",
    "            The name of the filename (same as the sample id)\n",
    "        num : int\n",
    "            The index field which counts the samples as we loop through them\n",
    "            \n",
    "    Output\n",
    "        ----------\n",
    "        dictionary item containing the formatted data so that we can read into the panda\n",
    "        dataframe and eventually make a data frame containing all the sampels.\n",
    "\n",
    "    '''\n",
    "    \n",
    "    # read the data as an numpy array because later we want to merge it\n",
    "    data_file           = np.loadtxt(filename, skiprows=1, delimiter=\",\")\n",
    "    sample_id           = filename.split('/')[-1].split('.')[0]\n",
    "    dict_out            = {}\n",
    "    egams               = True # set this to True if the data is from GCMS\n",
    "\n",
    "    df = pd.read_csv(label_file)             \n",
    "    indx = df['sample_id'] == sample_id\n",
    "    \n",
    "    if (len(indx[indx]) > 0 and not egams):\n",
    "        dict_out =  {'Indx': num, 'sample_id': sample_id, 'Data': {'time': [data_file[:, 0]], \\\n",
    "                                                                    'mass': [data_file[:, 1]], \\\n",
    "                                                                    'intensity': [data_file[:, 2]]}, \\\n",
    "                    'label': df[df['sample_id'] == sample_id].iloc[0][1:].to_dict()}\n",
    "    elif (len(indx[indx]) > 0 and egams):\n",
    "        dict_out =  {'Indx': num, 'sample_id': sample_id, 'Data': {'time': [data_file[:, 0]], \\\n",
    "                                                                   'temp': [data_file[:, 1]], \\\n",
    "                                                                   'mass_over_charge': [data_file[:, 2]], \\\n",
    "                                                                   'abundance': [data_file[:, 3]]}, \\\n",
    "                    'label': df[df['sample_id'] == sample_id].iloc[0][1:].to_dict()}     \n",
    "\n",
    "            \n",
    "    return dict_out    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c43a9742",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_data_out  =  pd.DataFrame(get_data_cube(file_names[0], 0), index=[0])\n",
    "\n",
    "for i in range(len(file_names)):\n",
    "    pd_data_out.loc[i] = get_data_cube(file_names[i], i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "192185cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_data_out.to_csv('test_data_egams.csv', sep=',', index=True, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "459b7ade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "447"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pd_data_out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
