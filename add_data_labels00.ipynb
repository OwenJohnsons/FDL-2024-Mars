{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "47f8af98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ae3243",
   "metadata": {},
   "source": [
    "This notebook takes all the test and training samples and adds labels using the data avialable in the GCMS and EGAMS contests. The function takes the filenames which correspond to the sample id and then add labels which are in two sets:\n",
    "1. label: \"basalt, carbonate, chloride, iron_oxide, oxalate, oxychlorine, phyllosilicate, silicate, sulfate, sulfide\"\n",
    "2. label_1: \"aromatic, hydrocarbon, carboxylic acid, nitrogen_bearing_compound, chlorine_bearing_compound, sulfur_bearing_compound, alcohol, other_oxygen_bearing_compound, mineral\n",
    "\n",
    "The generated dataframe includes four columns such that:\n",
    "column_1 : index_id (starting from 1 to the number of samples)\n",
    "column_2 : sample_id from GSFC\n",
    "column_3 : sample data with columns representing 'time' at which the measurement is made, 'mass' of the module, and 'intensity' of the sample released\n",
    "column_4 : label set 1\n",
    "column_5 : label_1 set 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f32de22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the file names, and label names for the dataset you want to use\n",
    "dir_samples      = '/home/arushi/Desktop/FDL_2024/Data_from_Goddard/GCMS_challenge/train_features-003/'\n",
    "dir_label_name   = '/home/arushi/Desktop/FDL_2024/Data_from_Goddard/GCMS_challenge/GCMS_challenge-20240617T192949Z-002/GCMS_challenge/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "56d5f63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test to see if we get the sample id from the filename correctly\n",
    "file_names  = glob(dir_samples + 'train_features/' + '*.csv')\n",
    "label_file  = dir_label_name + 'train_labels.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a9f1ed72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Indx': 1,\n",
       " 'sample_id': 'S0048',\n",
       " 'Data': {'time': [array([ 0.0422  ,  0.0422  ,  0.0422  , ..., 36.015633, 36.015633,\n",
       "          36.015633])],\n",
       "  'mass': [array([ 50.279495,  51.120758,  52.053543, ..., 531.709717, 533.026001,\n",
       "          534.64978 ])],\n",
       "  'intensity': [array([12810., 24765., 16562., ...,  1059.,   983.,  4678.])]},\n",
       " 'label': {'aromatic': 1,\n",
       "  'hydrocarbon': 0,\n",
       "  'carboxylic_acid': 0,\n",
       "  'nitrogen_bearing_compound': 0,\n",
       "  'chlorine_bearing_compound': 0,\n",
       "  'sulfur_bearing_compound': 0,\n",
       "  'alcohol': 0,\n",
       "  'other_oxygen_bearing_compound': 0,\n",
       "  'mineral': 0}}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this cell is just for previweing how the output data would be structured\n",
    "num = 1\n",
    "\n",
    "data_file           = np.loadtxt(file_names[0], skiprows=1, delimiter=\",\")\n",
    "df = pd.read_csv(label_file) \n",
    "sample_id           = file_names[0].split('/')[-1].split('.')[0]\n",
    "df[df['sample_id'] == file_names[0].split('/')[-1].split('.')[0]].iloc[0][1:].to_dict()\n",
    "my_dict =  {'Indx': num, 'sample_id': sample_id, 'Data': {'time': [data_file[:, 0]], \\\n",
    "                                                          'mass': [data_file[:, 1]], \\\n",
    "                                                          'intensity': [data_file[:, 2]]}, \\\n",
    "           'label': df[df['sample_id'] == file_names[0].split('/')[-1].split('.')[0]].iloc[0][1:].to_dict()}\n",
    "my_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "288e9eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_cube (filename, num):\n",
    "    '''\n",
    "    This function takes the mass spectrometer data from the sample and generates \n",
    "    a dictionary with the columns specifying the index, sample_id, mass spec data, \n",
    "    and lables. We do this to create a merged data from all the samples with their\n",
    "    labels attached\n",
    "    \n",
    "    Input Parameters\n",
    "        ----------\n",
    "        filename : str\n",
    "            The name of the filename (same as the sample id)\n",
    "        num : int\n",
    "            The index field which counts the samples as we loop through them\n",
    "            \n",
    "    Output\n",
    "        ----------\n",
    "        dictionary item containing the formatted data so that we can read into the panda\n",
    "        dataframe and eventually make a data frame containing all the sampels.\n",
    "\n",
    "    '''\n",
    "    \n",
    "    # read the data as an numpy array because later we want to merge it\n",
    "    data_file           = np.loadtxt(filename, skiprows=1, delimiter=\",\")\n",
    "    sample_id           = filename.split('/')[-1].split('.')[0]\n",
    "    dict_out            = {}\n",
    "    egams               = True # set this to True if the data is from GCMS\n",
    "\n",
    "    df = pd.read_csv(label_file)             \n",
    "    indx = df['sample_id'] == sample_id\n",
    "    \n",
    "    if (len(indx[indx]) > 0 and not egams):\n",
    "        dict_out =  {'Indx': num, 'sample_id': sample_id, 'Data': {'time': [data_file[:, 0]], \\\n",
    "                                                                    'mass': [data_file[:, 1]], \\\n",
    "                                                                    'intensity': [data_file[:, 2]]}, \\\n",
    "                    'label': df[df['sample_id'] == sample_id].iloc[0][1:].to_dict()}\n",
    "    elif (len(indx[indx]) > 0 and not egams):\n",
    "        dict_out =  {'Indx': num, 'sample_id': sample_id, 'Data': {'time': [data_file[:, 0]], \\\n",
    "                                                                   'temp': [data_file[:, 1]], \\\n",
    "                                                                   'mass_over_charge': [data_file[:, 2]], \\\n",
    "                                                                   'abundance': [data_file[:, 3]]}, \\\n",
    "                    'label': df[df['sample_id'] == sample_id].iloc[0][1:].to_dict()}     \n",
    "\n",
    "            \n",
    "    return dict_out    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c43a9742",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 3 is out of bounds for axis 1 with size 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[58], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pd_data_out  \u001b[38;5;241m=\u001b[39m  pd\u001b[38;5;241m.\u001b[39mDataFrame(get_data_cube(file_names[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m0\u001b[39m), index\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(file_names)):\n\u001b[1;32m      4\u001b[0m     pd_data_out\u001b[38;5;241m.\u001b[39mloc[i] \u001b[38;5;241m=\u001b[39m get_data_cube(file_names[i], i)\n",
      "Cell \u001b[0;32mIn[57], line 40\u001b[0m, in \u001b[0;36mget_data_cube\u001b[0;34m(filename, num)\u001b[0m\n\u001b[1;32m     32\u001b[0m     dict_out \u001b[38;5;241m=\u001b[39m  {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIndx\u001b[39m\u001b[38;5;124m'\u001b[39m: num, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msample_id\u001b[39m\u001b[38;5;124m'\u001b[39m: sample_id, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData\u001b[39m\u001b[38;5;124m'\u001b[39m: {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m: [data_file[:, \u001b[38;5;241m0\u001b[39m]], \\\n\u001b[1;32m     33\u001b[0m                                                                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmass\u001b[39m\u001b[38;5;124m'\u001b[39m: [data_file[:, \u001b[38;5;241m1\u001b[39m]], \\\n\u001b[1;32m     34\u001b[0m                                                                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mintensity\u001b[39m\u001b[38;5;124m'\u001b[39m: [data_file[:, \u001b[38;5;241m2\u001b[39m]]}, \\\n\u001b[1;32m     35\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m: df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msample_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m sample_id]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m:]\u001b[38;5;241m.\u001b[39mto_dict()}\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\u001b[38;5;28mlen\u001b[39m(indx[indx]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m gcms):\n\u001b[1;32m     37\u001b[0m     dict_out \u001b[38;5;241m=\u001b[39m  {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIndx\u001b[39m\u001b[38;5;124m'\u001b[39m: num, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msample_id\u001b[39m\u001b[38;5;124m'\u001b[39m: sample_id, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData\u001b[39m\u001b[38;5;124m'\u001b[39m: {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m: [data_file[:, \u001b[38;5;241m0\u001b[39m]], \\\n\u001b[1;32m     38\u001b[0m                                                                \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtemp\u001b[39m\u001b[38;5;124m'\u001b[39m: [data_file[:, \u001b[38;5;241m1\u001b[39m]], \\\n\u001b[1;32m     39\u001b[0m                                                                \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmass_over_charge\u001b[39m\u001b[38;5;124m'\u001b[39m: [data_file[:, \u001b[38;5;241m2\u001b[39m]], \\\n\u001b[0;32m---> 40\u001b[0m                                                                \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mabundance\u001b[39m\u001b[38;5;124m'\u001b[39m: [data_file[:, \u001b[38;5;241m3\u001b[39m]]}, \\\n\u001b[1;32m     41\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m: df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msample_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m sample_id]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m:]\u001b[38;5;241m.\u001b[39mto_dict()}     \n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dict_out\n",
      "\u001b[0;31mIndexError\u001b[0m: index 3 is out of bounds for axis 1 with size 3"
     ]
    }
   ],
   "source": [
    "pd_data_out  =  pd.DataFrame(get_data_cube(file_names[0], 0), index=[0])\n",
    "\n",
    "for i in range(len(file_names)):\n",
    "    pd_data_out.loc[i] = get_data_cube(file_names[i], i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "192185cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_data_out.to_csv('train_data_gcms.csv', sep=',', index=True, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "459b7ade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "447"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pd_data_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabd6ede",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72c53b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
